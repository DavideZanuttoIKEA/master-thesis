{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f673940-0f6d-488d-96f6-deacef225af4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to evaluation_results\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import distance\n",
    "import json\n",
    "\n",
    "# Initialize the model\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "# Read data\n",
    "topics_df = pd.read_csv('csv/5ShotLlama3+Keyphrases_Topics.csv', sep=\";\")\n",
    "ground_truth_df = pd.read_csv('csv/GroundTruthV2.csv', sep=\";\")\n",
    "\n",
    "# Parse the GroundTruth field into a dictionary\n",
    "def parse_ground_truth(ground_truth_str):\n",
    "    return {k.strip(): int(v.strip()) for k, v in (item.split(':') for item in ground_truth_str.split(','))}\n",
    "\n",
    "ground_truth_df['TopicsCount'] = ground_truth_df['TopicsCount'].apply(parse_ground_truth)\n",
    "\n",
    "\n",
    "# Function to calculate cosine similarity\n",
    "def calculate_similarity(embeddings1, embeddings2):\n",
    "    return util.pytorch_cos_sim(embeddings1, embeddings2)\n",
    "\n",
    "\n",
    "# Calculate diversity based on embeddings\n",
    "def calculate_diversity(embeddings):\n",
    "    n = len(embeddings)\n",
    "    if n < 2:\n",
    "        return 0  # No diversity score if less than 2 topics\n",
    "    distances = []\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            dist = 1 - util.pytorch_cos_sim(embeddings[i], embeddings[j])\n",
    "            adjusted_dist = dist / 2  # Adjusting the range to 0 to 1\n",
    "            distances.append(adjusted_dist)\n",
    "    return sum(distances) / len(distances) if distances else 0\n",
    "\n",
    "\n",
    "def compute_metrics(article_id, topics, ground_truth):\n",
    "    ground_truth_topics = ground_truth[article_id]\n",
    "    ground_truth_sorted = sorted(ground_truth_topics.items(), key=lambda item: item[1], reverse=True)\n",
    "    \n",
    "    N = min(8, len(ground_truth_sorted))\n",
    "    top_n_ground_truth = dict(ground_truth_sorted[:N])\n",
    "    correct_topics = set(topics).intersection(top_n_ground_truth.keys())\n",
    "    \n",
    "    ## EXACT-MATCHING\n",
    "    \n",
    "    # Exact-Match Precision\n",
    "    ExactMatch_precision = len(correct_topics) / len(topics) if topics else 0\n",
    "    \n",
    "    # Exact-Match Weighted Recall\n",
    "    correct_weights = sum(top_n_ground_truth[topic] for topic in correct_topics)\n",
    "    total_weight_top_n = sum(top_n_ground_truth.values())\n",
    "    ExactMatch_weighted_recall = correct_weights / total_weight_top_n if total_weight_top_n else 0\n",
    "    \n",
    "    # Exact-Match F1 Score\n",
    "    ExactMatch_f1_score = 2 * (ExactMatch_precision * ExactMatch_weighted_recall) / (ExactMatch_precision + ExactMatch_weighted_recall) if ExactMatch_precision + ExactMatch_weighted_recall != 0 else 0\n",
    "    \n",
    "    ## EMBEDDING-BASED\n",
    "    \n",
    "    # Embeddings\n",
    "    topic_embeddings = model.encode(list(topics))\n",
    "    gt_topic_embeddings = model.encode(list(top_n_ground_truth.keys()))\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    similarity_matrix = calculate_similarity(topic_embeddings, gt_topic_embeddings)\n",
    "    \n",
    "    # Compute Precision\n",
    "    max_similarity_per_identified = similarity_matrix.max(dim=1).values\n",
    "    Embeddings_precision = max_similarity_per_identified.mean().item()\n",
    "    \n",
    "    # Compute Weighted Recall\n",
    "    max_similarity_per_gt = similarity_matrix.max(dim=0).values\n",
    "    weighted_similarity_scores = max_similarity_per_gt * torch.tensor(list(top_n_ground_truth.values()))\n",
    "    Embeddings_weighted_recall = weighted_similarity_scores.sum().item() / sum(top_n_ground_truth.values())\n",
    "    \n",
    "    # Compute F1 Score\n",
    "    if Embeddings_precision + Embeddings_weighted_recall == 0:\n",
    "        Embeddings_f1_score = 0\n",
    "    else:\n",
    "        Embeddings_f1_score = 2 * (Embeddings_precision * Embeddings_weighted_recall) / (Embeddings_precision + Embeddings_weighted_recall)\n",
    "    \n",
    "    ## TOPIC DIVERSITY\n",
    "    \n",
    "    diversity_score = calculate_diversity(topic_embeddings)\n",
    "    \n",
    "    return ExactMatch_precision, ExactMatch_weighted_recall, ExactMatch_f1_score, Embeddings_precision, Embeddings_weighted_recall, Embeddings_f1_score, diversity_score\n",
    "\n",
    "# Apply metrics to all articles\n",
    "ExactMatch_results = []\n",
    "Embeddings_results = []\n",
    "Diversity_results = []\n",
    "\n",
    "for _, row in topics_df.iterrows():\n",
    "    article_id = row['ArticleID']\n",
    "    topics = row['Topics'].split(', ')\n",
    "    \n",
    "    ExactMatch_precision, ExactMatch_weighted_recall, ExactMatch_f1_score, Embeddings_precision, Embeddings_weighted_recall, Embeddings_f1_score, diversity = compute_metrics(article_id, topics, ground_truth_df.set_index('ArticleID')['TopicsCount'])\n",
    "    \n",
    "    ExactMatch_results.append({'ArticleID': article_id, 'ExactMatch_precision': ExactMatch_precision, 'ExactMatch_weighted_recall': ExactMatch_weighted_recall, 'ExactMatch_f1_score': ExactMatch_f1_score})\n",
    "    Embeddings_results.append({'ArticleID': article_id, 'Embeddings_precision': Embeddings_precision, 'Embeddings_weighted_recall': Embeddings_weighted_recall, 'Embeddings_f1_score': Embeddings_f1_score})\n",
    "    Diversity_results.append({'ArticleID': article_id, 'Diversity': diversity})\n",
    "\n",
    "    \n",
    "ExactMatch_results_df = pd.DataFrame(ExactMatch_results)\n",
    "Embeddings_results_df = pd.DataFrame(Embeddings_results)\n",
    "Diversity_results_df = pd.DataFrame(Diversity_results)\n",
    "\n",
    "\n",
    "ExactMatch_final_precision = ExactMatch_results_df['ExactMatch_precision'].mean()\n",
    "ExactMatch_final_weighted_recall = ExactMatch_results_df['ExactMatch_weighted_recall'].mean()\n",
    "ExactMatch_final_f1_score = ExactMatch_results_df['ExactMatch_f1_score'].mean()\n",
    "\n",
    "Embeddings_final_precision = Embeddings_results_df['Embeddings_precision'].mean()\n",
    "Embeddings_final_weighted_recall = Embeddings_results_df['Embeddings_weighted_recall'].mean()\n",
    "Embeddings_final_f1_score = Embeddings_results_df['Embeddings_f1_score'].mean()\n",
    "\n",
    "final_diversity = Diversity_results_df['Diversity'].mean()\n",
    "\n",
    "ExactMatch_final_scores = {'Final Precision': ExactMatch_final_precision, 'Final Weighted Recall': ExactMatch_final_weighted_recall, 'Final F1 Score': ExactMatch_final_f1_score}\n",
    "Embeddings_scores = {'Final Precision': Embeddings_final_precision, 'Final Weighted Recall': Embeddings_final_weighted_recall, 'Final F1 Score': Embeddings_final_f1_score}\n",
    "\n",
    "\n",
    "def save_results_json(ground_truth_category, filename, ExactMatch_results_df, Embeddings_results_df, Diversity_results_df):\n",
    "    data_path = \"evaluation_results.json\"\n",
    "\n",
    "    try:\n",
    "        with open(data_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        data = {}\n",
    "\n",
    "    # Update the nested structure\n",
    "    exact_method_results = {\n",
    "        \"mean\": {\n",
    "            \"Precision\": ExactMatch_final_precision,\n",
    "            \"Weighted Recall\": ExactMatch_final_weighted_recall,\n",
    "            \"F1 Score\": ExactMatch_final_f1_score\n",
    "        },\n",
    "        \"articles\": ExactMatch_results_df.to_dict(orient=\"records\")\n",
    "    }\n",
    "    \n",
    "    embeddings_method_results = {\n",
    "        \"mean\": {\n",
    "            \"Precision\": Embeddings_final_precision,\n",
    "            \"Weighted Recall\": Embeddings_final_weighted_recall,\n",
    "            \"F1 Score\": Embeddings_final_f1_score\n",
    "        },\n",
    "        \"articles\": Embeddings_results_df.to_dict(orient=\"records\")\n",
    "    }\n",
    "\n",
    "    diversity_method_results = {\n",
    "        'Diversity': final_diversity,\n",
    "        \"articles\": Diversity_results_df.to_dict(orient=\"records\")\n",
    "    }\n",
    "    \n",
    "    \n",
    "    data.setdefault(ground_truth_category, {}).setdefault(filename, {})[\"Exact-Matching\"] = exact_method_results\n",
    "    data.setdefault(ground_truth_category, {}).setdefault(filename, {})[\"Embedding-Based\"] = embeddings_method_results\n",
    "    data.setdefault(ground_truth_category, {}).setdefault(filename, {})[\"Diversity\"] = diversity_method_results\n",
    "\n",
    "    with open(data_path, \"w\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "# Call the function with desired ground truth category and method\n",
    "save_results_json(\"GroundTruthV2\", \"5ShotLlama3+Keyphrases_Topics.csv\", ExactMatch_results_df, Embeddings_results_df, Diversity_results_df)\n",
    "print(\"Results saved to evaluation_results\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcaf70d-214f-49c4-8ecd-3418fee0006a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m120"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
