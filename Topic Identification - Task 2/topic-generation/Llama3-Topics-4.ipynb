{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "836feb37-21b2-475d-81e8-6b55b23deb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers\n",
      "  Cloning https://github.com/huggingface/transformers to /var/tmp/pip-req-build-q_kqw_td\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /var/tmp/pip-req-build-q_kqw_td\n",
      "  Resolved https://github.com/huggingface/transformers to commit 2b9e252b16396c926dad0e3c31802b4af8004e93\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.42.0.dev0) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.42.0.dev0) (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.42.0.dev0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.42.0.dev0) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.42.0.dev0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.42.0.dev0) (2024.4.28)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.42.0.dev0) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers==4.42.0.dev0) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.42.0.dev0) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.42.0.dev0) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.42.0.dev0) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.42.0.dev0) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.42.0.dev0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.42.0.dev0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.42.0.dev0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.42.0.dev0) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b368ae8c-4abc-4736-beae-a0bb13497e38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "client = bigquery.Client()\n",
    "\n",
    "query = \"\"\" SELECT Distinct art_id as text FROM `ingka-feed-student-dev.RR.RatingsReviews` AS rr\n",
    "            INNER JOIN `ingka-feed-student-dev.RR.product_categories` AS pc \n",
    "            ON rr.art_id = SPLIT(pc.global_id, ',')[SAFE_OFFSET(1)] \n",
    "            WHERE country_code = 'us' and PRODUCT_AREA = 'Open storage' \"\"\"\n",
    "\n",
    "query_job = client.query(query)\n",
    "\n",
    "art_ids = []\n",
    "\n",
    "for art_id in query_job:\n",
    "     art_ids.append(art_id.text)\n",
    "\n",
    "print(len(art_ids))\n",
    "art_ids = art_ids[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c791a93-e709-40da-8949-9c4ead815751",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_reviews = []\n",
    "\n",
    "for art_id in art_ids:\n",
    "    query = f\"\"\" SELECT concat(title,'. ',text) as text FROM `ingka-feed-student-dev.RR.RatingsReviews` AS rr\n",
    "                INNER JOIN `ingka-feed-student-dev.RR.product_categories` AS pc \n",
    "                ON rr.art_id = SPLIT(pc.global_id, ',')[SAFE_OFFSET(1)] \n",
    "                WHERE country_code = 'us' and PRODUCT_AREA = 'Open storage' and art_id = '{art_id}'\n",
    "                ORDER BY inserted_on DESC \"\"\"\n",
    "\n",
    "    query_job = client.query(query)\n",
    "\n",
    "    article_reviews = []\n",
    "\n",
    "    for review in query_job:\n",
    "         article_reviews.append(review.text)\n",
    "\n",
    "    all_reviews.append(article_reviews)\n",
    "len(all_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d30d37e0-8324-4809-861e-a67b82dfeafb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import download\n",
    "download('punkt')\n",
    "\n",
    "def count_tokens_in_reviews(review_list):\n",
    "    total_tokens = 0\n",
    "    for review in review_list:\n",
    "        total_tokens += len(word_tokenize(review))\n",
    "    return total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0175d860-2dce-431b-bc6a-1f3ee61812cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def categorize_reviews_by_token_count(reviews, max_tokens):\n",
    "    above_limit = []\n",
    "    below_limit = []\n",
    "\n",
    "    for review_group in reviews:\n",
    "        token_count = count_tokens_in_reviews(review_group)\n",
    "        if token_count > max_tokens:\n",
    "            above_limit.append(review_group)\n",
    "        else:\n",
    "            below_limit.append(review_group)\n",
    "    \n",
    "    return below_limit, above_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f2cb2f3-631c-48a1-b9f7-9367cf44cc9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Products with <= 5000 tokens:\n",
      "1\n",
      "Products with > 5000 tokens:\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Applying the function\n",
    "below_limit, above_limit = categorize_reviews_by_token_count(all_reviews, max_tokens=5000)\n",
    "\n",
    "print(\"Products with <= 5000 tokens:\")\n",
    "print(len(below_limit))\n",
    "\n",
    "print(\"Products with > 5000 tokens:\")\n",
    "print(len(above_limit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb8d976b-4c94-4056-b3a1-a9507b541629",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(above_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8c33015-cefc-43e7-8d18-21851144522f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Cost Cutting Garbage, ignore Older Reviews. I bought one of these guys in 2015 and it went together like a breeze - its\\nstill standing after being moved across the state several times. This one I got in 2024 - EVERY shelf piece is hollow with their cardboard honeycomb stuff inside (formerly plywood) and MUCH thinner wall structure on each piece. The shelves flexed so badly it doesn't slot together and leaves huge gaps, plus we knocked a hole into the side panel of it with a soft rubber mallet trying to get it lined up. And yet, Ikea has the gall to charge more for it? Spare me, please.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "above_limit[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34bb12f8-7f0f-4bca-b8d9-567fdcffaf76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Ensure you have the NLTK tokenizers\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Define the path to your CSV file\n",
    "file_path = '5Shot_FullReviewsKeyphrases_OpenStorageUS.csv'\n",
    "\n",
    "# Function to count tokens\n",
    "def count_tokens(text):\n",
    "    return len(word_tokenize(text))\n",
    "\n",
    "above_limit_final = []\n",
    "\n",
    "for reviews in above_limit:\n",
    "    start_reviews = []\n",
    "    with open(file_path, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile, delimiter=';')\n",
    "        for row in reader:\n",
    "            review_text = row['Reviews']\n",
    "            if review_text in reviews: \n",
    "                keyphrases = row['Keyphrases'].split(',')\n",
    "                keyphrase_count = len(keyphrases)\n",
    "                start_reviews.append((review_text, keyphrase_count, count_tokens(review_text)))\n",
    "                \n",
    "    # Sort reviews by the number of keyphrases, descending\n",
    "    reviews_sorted = sorted(start_reviews, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Select reviews until the token count exceeds 5000\n",
    "    selected_reviews = []\n",
    "    current_token_count = 0\n",
    "    for review, kp_count, tokens in reviews_sorted:\n",
    "        if current_token_count + tokens > 5000:\n",
    "            break\n",
    "        selected_reviews.append(review)\n",
    "        current_token_count += tokens\n",
    "    \n",
    "    above_limit_final.append(selected_reviews)\n",
    "\n",
    "len(above_limit_final)\n",
    "len(above_limit_final[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f31c423c-b8ca-4565-9b4d-00b3d0533f09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mabove_limit_final\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "len(above_limit_final[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab2bc98-7109-43a9-abf1-7e340e61dab8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(above_limit[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "936ad20e-fddd-44d5-820e-4840d1adc0fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_reviews = below_limit + above_limit_final\n",
    "len(all_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7356428a-7159-4835-85d1-f8d7f3bd1b17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.31.0.dev0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (24.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.3.0)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.23.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa99534eeb04fda917dd4f8c9a6db0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "access_token = \"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\"\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    token=access_token,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e623b3e7-26fc-4994-b3b1-0cb5ffe95252",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Design, Comfort, Quality, Support, Ease, Stability, Value, Timelessness\n",
      "Design, Comfort, Quality, Support, Stability, Ease, Value, Timelessness\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "answers = []\n",
    "\n",
    "for reviews in all_reviews:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful chatbot who only answer with a comma-separated list of the requested topics and no additional text\"},\n",
    "        {\"role\": \"user\", \"content\": 'From these reviews, generate maximum 10 non-redundant topics. Topics should be 1 word maximum, can be 2 or 3 if necessary. The topics should be about qualities and characteristics of the products (ex: quality, price, …) and not names of objects (like Books, shelves, …). The topics should be names (ex: not durable but durability). Answer only with a comma-separated list of the topics you identify. Reviews: \"Perfect Simple TV Stand. I actually went in to buy something different, but when I saw the possibility of changing the orientation of this bookshelf and combining with a stand (maybe not even necessary but I think it enhances the appearance), I bought this instead. It seems sturdy and durable, looks good, I’m happy with my purchase. I put a couple of Fossta bins in mine but there are many other options for the storage bays.\",\"Good quality. Good looking and quality\",\"TV Stand With Base. A Simple, clean and light weight unit when cocmbined with the metal base works well as a tv stand in my case a 55\" TV. I\\'ll probably get the black baskets which fit perfectly into this or craft something simple to cover the back. I was worried that the round bottom of the legs would not be secure into the sqare legs of the base but they seem to fit without movement. But be aware that the top is not secured in any way- meaning you can lift this kallax right up out of the base. Of course the weight of the tv will prevent that from occurring but ikea should have engineered a way to secure theKallax base to this Kallax unit.\",\"IKEA perfection. IKEA perfection\"\t,\"Sturdy, good quality and minimalist, Love it!. This media console is just what I needed! It simple, sturdy and minimalist. It was easy to built. Thanks to the visual instructions! Very good quality and it\\'s a minimalist piece. It adds to the TV room without interfering with the rest of the furniture but adding weigh to it, which was necessary. It is also useful because I store a blanket in one of the shelves, my sleepers in another one and tv stuff...\",\t\"Nice piece. I like it.\",\"Simple and elegant. Simple and elegant\".'},\n",
    "        {\"role\": \"assistant\", \"content\": \"Durability, Quality, Appearance, Security, Minimalism, Flexibility\"},\n",
    "        {\"role\": \"user\", \"content\": f'From these reviews, generate maximum 10 non-redundant topics. Topics should be 1 word maximum, can be 2 or 3 if necessary. The topics should be about qualities and characteristics of the products (ex: quality, price, …) and not names of objects (like Books, shelves, …). The topics should be names (ex: not durable but durability). Answer only with a comma-separated list of the topics you identify. Reviews: {reviews}'},\n",
    "    ]\n",
    "\n",
    "    prompt = pipeline.tokenizer.apply_chat_template(\n",
    "            messages, \n",
    "            tokenize=False, \n",
    "            add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    terminators = [\n",
    "        pipeline.tokenizer.eos_token_id,\n",
    "        pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "\n",
    "    outputs = pipeline(\n",
    "    prompt,\n",
    "    max_new_tokens=30,\n",
    "    eos_token_id=terminators,    \n",
    "    pad_token_id=pipeline.tokenizer.eos_token_id,\n",
    "    do_sample=True,\n",
    "    temperature=0.3,\n",
    "    top_p=0.9,\n",
    "    )\n",
    "\n",
    "    answer=outputs[0][\"generated_text\"][len(prompt):]\n",
    "    print(answer)\n",
    "    answers.append(answer)\n",
    "    if (answers.index(answer) + 1) % 10 == 0: \n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(f\"{answers.index(answer) + 1}th file completed in {elapsed_time} seconds.\")\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ec1a4d-9fcf-4823-8faa-56fd34d0d74d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(count_tokens_in_reviews(all_reviews[210]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75c52a0-d5b8-4128-b7d1-335aa5d104a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "[answer.replace('\\n', ' ') for answer in answers]\n",
    "answers[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764ebc6f-4961-4222-bf14-75b89f50c407",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "filename = 'productTopics_llama3.csv'\n",
    "\n",
    "# Writing to the csv file\n",
    "with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    # Creating a csv writer object with quoting set to quote all fields\n",
    "    csvwriter = csv.writer(csvfile, delimiter=';')\n",
    "    \n",
    "    # Writing the columns\n",
    "    csvwriter.writerow(['ArticleID', 'Topics'])\n",
    "    \n",
    "    # Writing the data\n",
    "    for article, answer in zip(art_ids, answers):\n",
    "        csvwriter.writerow([article, answer])\n",
    "\n",
    "print(f'CSV file \"{filename}\" has been written successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911608a2-0220-4a90-93e4-d6b1c8d4eafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def process_csv(input_file, output_file):\n",
    "    with open(input_file, mode='r', newline='', encoding='utf-8') as infile, \\\n",
    "         open(output_file, mode='w', newline='', encoding='utf-8') as outfile:\n",
    "        \n",
    "        reader = csv.reader(infile, delimiter=';')\n",
    "        writer = csv.writer(outfile, delimiter=';')\n",
    "        \n",
    "        for row in reader:\n",
    "            # Check if the row has at least two columns\n",
    "            if len(row) >= 2:\n",
    "                # Find the position of the first colon in the second column\n",
    "                colon_index = row[1].find(':')\n",
    "                # Remove everything before and including the colon, if it exists\n",
    "                if colon_index != -1:\n",
    "                    row[1] = row[1][colon_index + 1:].strip()\n",
    "            writer.writerow(row)\n",
    "\n",
    "# Replace 'input.csv' and 'output.csv' with your actual file paths\n",
    "process_csv('aproductTopics_llama3.csv', 'productTopics_llama3.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c04b676-8b7d-4acc-9631-27ca465862d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m120"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
