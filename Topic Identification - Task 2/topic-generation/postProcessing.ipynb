{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f36ea204-bfc1-416b-8a22-7360cf203764",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f40b95e-20b1-4bf0-b64b-f6caa62643e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### POST PROCESSING - ADDITION OF KEYPHRASES\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV files\n",
    "df1 = pd.read_csv('csv/GTv2/5ShotLlama3KeyphrasesKMeans.csv', sep=';')\n",
    "df2 = pd.read_csv('csv/GTv2/5ShotLlama3Reviews.csv', sep=';')\n",
    "\n",
    "# Ensure Topics are read as strings and handle NaN values\n",
    "df1['Topics'] = df1['Topics'].fillna('').astype(str)\n",
    "df2['Topics'] = df2['Topics'].fillna('').astype(str)\n",
    "\n",
    "# Convert comma-separated string to list\n",
    "df1['Topics'] = df1['Topics'].apply(lambda x: x.split(',') if x != '' else [])\n",
    "df2['Topics'] = df2['Topics'].apply(lambda x: x.split(',') if x != '' else [])\n",
    "\n",
    "# Merging topics with conditions\n",
    "for index, row in df1.iterrows():\n",
    "    article_id = row['ArticleID']\n",
    "    topics_to_add = row['Topics']\n",
    "\n",
    "    # Find the corresponding rows in the second dataframe\n",
    "    match_indices = df2[df2['ArticleID'] == article_id].index\n",
    "    for idx in match_indices:\n",
    "        existing_topics = df2.at[idx, 'Topics']\n",
    "        updated_topics = existing_topics.copy()\n",
    "\n",
    "        # Add new topics if not present and check length constraint\n",
    "        for topic in topics_to_add:\n",
    "            if topic not in existing_topics and topic != ' Ease' and topic!= ' Assembly' and len(updated_topics) < 10:\n",
    "                updated_topics.append(topic)\n",
    "\n",
    "        # Update the second dataframe\n",
    "        df2.at[idx, 'Topics'] = updated_topics\n",
    "\n",
    "# Convert the topics list back to a string\n",
    "df2['Topics'] = df2['Topics'].apply(lambda x: ','.join(x) if x else '')\n",
    "\n",
    "# Save the updated second file\n",
    "df2.to_csv('csv/GTv2/H10topics-5shotReviews.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6087e8de-d9ed-41da-87cb-95356264d735",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Art Ids: ['70301542', '19294535', '89442655', '90301555', '69329387', '79442689', '39442672', '09442678', '90510865', '89278259', '29278304', '80401292', '29442615', '69442680', '50454507', '19189030', '59442685', '49442676', '70538846', '19442654', '29481701', '40501892', '49189203', '80487813', '19442692', '59189472', '79278250', '59294557', '99017445', '79442694']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path=\"csv/GTv2/H10topics-5shotReviews.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path, sep=\";\")\n",
    "\n",
    "# Extract columns into separate arrays\n",
    "art_ids = df.iloc[:, 0].tolist()  # First column\n",
    "topics = df.iloc[:, 1].tolist()  # Second column\n",
    "\n",
    "art_ids = [str(number).zfill(8) for number in art_ids] #Add 0 padding for articleIDs\n",
    "\n",
    "# Print the arrays to verify\n",
    "print(\"Art Ids:\", art_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16763264-f9a4-4674-bce7-c175c57d7ff9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "client = bigquery.Client()\n",
    "\n",
    "all_reviews = []\n",
    "\n",
    "for art_id in art_ids:\n",
    "    query = f\"\"\"SELECT concat(title,'. ',text) as text FROM `ingka-feed-student-dev.RR.RatingsReviews` AS rr\n",
    "                INNER JOIN `ingka-feed-student-dev.RR.product_categories` AS pc \n",
    "                ON rr.art_id = SPLIT(pc.global_id, ',')[SAFE_OFFSET(1)] \n",
    "                WHERE country_code = 'us' and PRODUCT_AREA = 'Open storage' and art_id = '{art_id}'\n",
    "                ORDER BY inserted_on DESC \"\"\"\n",
    "\n",
    "    query_job = client.query(query)\n",
    "\n",
    "    article_reviews = []\n",
    "\n",
    "    for review in query_job:\n",
    "         article_reviews.append(review.text)\n",
    "\n",
    "    all_reviews.append(article_reviews)\n",
    "len(all_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1eb9976-0853-4cba-9903-c52d081696f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import download\n",
    "download('punkt')\n",
    "\n",
    "def count_tokens_in_reviews(review_list):\n",
    "    total_tokens = 0\n",
    "    for review in review_list:\n",
    "        total_tokens += len(word_tokenize(review))\n",
    "    return total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f914936-f028-4fba-b303-82ac4202ea3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_reviews_by_token_count(reviews, max_tokens):\n",
    "    above_limit = []\n",
    "    below_limit = []\n",
    "    index_above = []\n",
    "    \n",
    "    for review_group in reviews:\n",
    "        token_count = count_tokens_in_reviews(review_group)\n",
    "        if token_count > max_tokens:\n",
    "            above_limit.append(review_group)\n",
    "            index_above.append(all_reviews.index(review_group))\n",
    "        else:\n",
    "            below_limit.append(review_group)\n",
    "    \n",
    "    return below_limit, above_limit, index_above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce052bd2-27c1-41e2-a2c6-27651a9b83ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Products with <= 5000 tokens:\n",
      "29\n",
      "Products with > 5000 tokens:\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Applying the function\n",
    "below_limit, above_limit, index_above = categorize_reviews_by_token_count(all_reviews, max_tokens=5000)\n",
    "\n",
    "print(\"Products with <= 5000 tokens:\")\n",
    "print(len(below_limit))\n",
    "\n",
    "print(\"Products with > 5000 tokens:\")\n",
    "print(len(above_limit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dbade6b-e7d8-4aa0-b762-fd86190b341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('selected_reviews.json', mode='r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "    above_limit_final = data[\"reviews\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c6545fe-35ed-4304-9373-29def9c679dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements_to_move = [art_ids[i] for i in index_above]\n",
    "    \n",
    "remaining_elements = [art_id for i, art_id in enumerate(art_ids) if i not in index_above]\n",
    "\n",
    "art_ids = elements_to_move + remaining_elements\n",
    "\n",
    "all_reviews = above_limit_final + below_limit\n",
    "len(all_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ef23e44-79e2-4a29-8061-313a29044089",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'90510865'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "art_ids[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75841e7a-16f3-470c-8e1c-66f6fe659ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.31.0.dev0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (24.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.3.0)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.23.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf09690804284081a41be0b1d268d076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "access_token = \"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\"\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    token=access_token,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a196ae11-0ae9-4dd4-b107-50b09d9d64d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10th file completed in 41.79352641105652 seconds.\n",
      "20th file completed in 88.07239603996277 seconds.\n",
      "30th file completed in 129.66538786888123 seconds.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "answers = []\n",
    "\n",
    "for reviews, topic in zip(all_reviews, topics):\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\":\"You are a precise review analyzer. Your task is to count the frequency of user-specified topics in product reviews. Count both explicit mentions and implicit references that strongly relate to each topic. Report results only as 'topic: count' pairs. Only include topics with non-zero counts.\"},\n",
    "        {\"role\": \"user\", \"content\": f'Analyze the following product review and provide the count for each listed topic. Include both explicit mentions and implicit references that strongly relate to each topic. Report only as \"topic: count\" pairs for non-zero counts.Review Text: {reviews}.Topics to analyze: {topic}.Examples of implicit mentions:- Quality: \"good product\", \"great product\", \"works well\"- Appearance: \"looks great\", \"stylish\", \"attractive\"- Ease of Assembly: \"simple to put together\", \"no hassle setup\"- Functionality: \"works as expected\", \"does the job\"- Sturdiness: \"built to last\", \"sturdy\"- Value: \"worth the price\", \"cheap\"Provide your analysis as \"topic: count\" pairs only for topics with non-zero counts.'},\n",
    "        ]\n",
    "\n",
    "    prompt = pipeline.tokenizer.apply_chat_template(\n",
    "            messages, \n",
    "            tokenize=False, \n",
    "            add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    terminators = [\n",
    "        pipeline.tokenizer.eos_token_id,\n",
    "        pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "\n",
    "    outputs = pipeline(\n",
    "    prompt,\n",
    "    max_new_tokens=150,\n",
    "    eos_token_id=terminators,    \n",
    "    pad_token_id=pipeline.tokenizer.eos_token_id,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    "    )\n",
    "\n",
    "    answer=outputs[0][\"generated_text\"][len(prompt):]\n",
    "\n",
    "    answers.append(answer)\n",
    "    if (answers.index(answer) + 1) % 10 == 0: \n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(f\"{answers.index(answer) + 1}th file completed in {elapsed_time} seconds.\")\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "989f7591-4223-4ba1-825e-aa340f7dcc61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "answers = [answer.replace('\\n', ', ') for answer in answers]\n",
    "answers = [answer.replace('*', ', ') for answer in answers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b384f4c4-fea1-4631-862e-69c6bb457d5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv/GTv2/llamaPostProcessing.csv written!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "filename = \"csv/GTv2/llamaPostProcessing.csv\"\n",
    "\n",
    "def write_csv(filename, art_ids, answers):\n",
    "  \n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        # Creating a csv writer object with quoting set to quote all fields\n",
    "        csvwriter = csv.writer(csvfile, delimiter=';')\n",
    "\n",
    "        # Writing the columns\n",
    "        csvwriter.writerow(['ArticleID', 'Frequencies'])\n",
    "\n",
    "        # Writing the data with processed answers\n",
    "        for article, answer in zip(art_ids, answers):\n",
    "            csvwriter.writerow([article, answer])\n",
    "\n",
    "write_csv(filename, art_ids, answers)\n",
    "print(f\"{filename} written!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7beeb05a-c547-46f6-be57-5569eb1492ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('csv/GTv2/llamaPostProcessing.csv', sep=';')\n",
    "\n",
    "df['Frequencies'] = df['Frequencies'].apply(lambda x: x.split(':, ,', 1)[1] if ':' in x else x)\n",
    "\n",
    "df.to_csv('csv/GTv2/llamaPostProcessing.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa775648-606c-47ce-84f4-7a1bf5529905",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Frequencies'] = df['Frequencies'].apply(lambda x: x.split(\", ,\")[0] if \", ,\" in x else x)\n",
    "\n",
    "df.to_csv('csv/GTv2/llamaPostProcessing.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ddfe915-fa61-46e7-acbf-8ff1a86bbe6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File written!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_frequencies(freq_str):\n",
    "    # Remove any leading/trailing whitespace and split by comma\n",
    "    items = freq_str.strip().split(',')\n",
    "    topics = []\n",
    "    # Extract topics and frequencies, filter by frequency > 0\n",
    "    for item in items:\n",
    "        topic, freq = item.split(':')\n",
    "        if int(freq.strip()) > 0:\n",
    "            topics.append(topic.strip())\n",
    "    # Limit to a maximum of 8 topics\n",
    "    return topics[:8]\n",
    "\n",
    "def process_frequencies_freq(freq_str):\n",
    "    # Remove any leading/trailing whitespace and split by comma\n",
    "    items = freq_str.strip().split(',')\n",
    "    topics_with_freq = []\n",
    "    # Extract topics and frequencies\n",
    "    for item in items:\n",
    "        # Split by colon and strip spaces\n",
    "        topic_freq = item.split(':')\n",
    "        if len(topic_freq) == 2:\n",
    "            topic, freq = topic_freq\n",
    "            freq = int(freq.strip())\n",
    "            if freq > 0:\n",
    "                topics_with_freq.append((topic.strip(), freq))\n",
    "    # Sort topics by decreasing frequency\n",
    "    topics_with_freq.sort(key=lambda x: x[1], reverse=True)\n",
    "    # Extract topics and limit to a maximum of 8 topics\n",
    "    topics = [topic for topic, freq in topics_with_freq][:8]\n",
    "    return topics\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('csv/GTv2/llamaPostProcessing.csv', sep=';')\n",
    "\n",
    "df['Topics'] = df['Frequencies'].apply(process_frequencies)\n",
    "\n",
    "df['Topics'] = df['Topics'].apply(lambda x: ', '.join(x))\n",
    "\n",
    "df = df[['ArticleID', 'Topics']]\n",
    "\n",
    "df.to_csv('csv/GTv2/llamaPostProcessedKmeans.csv', index=False, sep=';')\n",
    "print(f\"File written!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62f0a4f-52d0-4563-b548-0b95262c11dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b7896d-907f-4178-8f33-20fc9f0bf35b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m120"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
