{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f12cf6b-955d-4d1b-bef3-47591822194d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['50339292', '30275861', '20423720', '40415601', '90324509']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "client = bigquery.Client()\n",
    "\n",
    "query = \"\"\" SELECT Distinct art_id as text FROM `ingka-feed-student-dev.RR.RatingsReviews` AS rr\n",
    "            INNER JOIN `ingka-feed-student-dev.RR.product_categories` AS pc \n",
    "            ON rr.art_id = SPLIT(pc.global_id, ',')[SAFE_OFFSET(1)] \n",
    "            WHERE country_code = 'us' and PRODUCT_AREA = 'Open storage' \"\"\"\n",
    "\n",
    "query_job = client.query(query)\n",
    "\n",
    "art_ids = []\n",
    "\n",
    "for art_id in query_job:\n",
    "     art_ids.append(art_id.text)\n",
    "\n",
    "print(len(art_ids))\n",
    "art_ids[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c2ec6a6-2d19-4548-8932-66f702ffb48f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'19189030',\n",
       " '19294535',\n",
       " '19442654',\n",
       " '19442692',\n",
       " '29278304',\n",
       " '29294554',\n",
       " '29442615',\n",
       " '29481701',\n",
       " '39442672',\n",
       " '40501892',\n",
       " '49189203',\n",
       " '49442676',\n",
       " '50454507',\n",
       " '59189472',\n",
       " '59294557',\n",
       " '59442685',\n",
       " '69329387',\n",
       " '69442680',\n",
       " '70301542',\n",
       " '70538846',\n",
       " '79278250',\n",
       " '79442689',\n",
       " '79442694',\n",
       " '80401292',\n",
       " '80487813',\n",
       " '89278259',\n",
       " '90301555',\n",
       " '90510865',\n",
       " '9442678',\n",
       " '99017445',\n",
       " '\\ufeffArticleID'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "sample_size = min(5, len(art_ids))\n",
    "\n",
    "# Read the blacklist file (if it exists) and store IDs in a set\n",
    "blacklist = set()\n",
    "try:\n",
    "    with open(\"csv/GroundTruth_complete.csv\", 'r') as f:\n",
    "        for line in f:\n",
    "            blacklist.add(line.strip().split(';')[0])\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "blacklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6a27cb8-0aa6-4bd3-8bef-d6e97d1a7fec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['69442642', '99442674', '29197572', '79278269', '20423720']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['70538846',\n",
       " '59189472',\n",
       " '99017445',\n",
       " '19189030',\n",
       " '50454507',\n",
       " '49189203',\n",
       " '79442694',\n",
       " '29278304',\n",
       " '29481701',\n",
       " '19294535',\n",
       " '09442678',\n",
       " '19442654',\n",
       " '39442672',\n",
       " '80487813',\n",
       " '29294554',\n",
       " '40501892',\n",
       " '<generator object <genexpr> at 0x7f3eb99b3bc0>',\n",
       " '19442692',\n",
       " '89278259',\n",
       " '59442685',\n",
       " '69329387',\n",
       " '80401292',\n",
       " '29442615',\n",
       " '90510865',\n",
       " '\\ufeffArticleID',\n",
       " '90301555',\n",
       " '79278250',\n",
       " '70301542',\n",
       " '49442676',\n",
       " '69442680',\n",
       " '79442689',\n",
       " '59294557']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter art_ids excluding entries in the first column of the blacklist\n",
    "filtered_art_ids = [art_id for art_id in art_ids if art_id not in blacklist]\n",
    "\n",
    "# Get a random sample of the filtered list (size at most 30)\n",
    "ground_truth_ids = random.sample(filtered_art_ids, sample_size)\n",
    "\n",
    "print(ground_truth_ids)\n",
    "\n",
    "blacklist.add(ground_truth_id for ground_truth_id in ground_truth_ids)\n",
    "\n",
    "blacklist = [str(number).zfill(8) for number in blacklist] #Add 0 padding for articleIDs\n",
    "\n",
    "blacklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47e2cf78-6731-460e-b55d-7badc833f81e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['49306872', '59481653', '49275088', '89442641', '79552908']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_art_ids = [art_id for art_id in art_ids if art_id not in blacklist]\n",
    "ground_truth_ids = random.sample(filtered_art_ids, sample_size)\n",
    "\n",
    "ground_truth_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e091f51-ce69-433f-9985-0d6cd1bab43f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_reviews = []\n",
    "\n",
    "for art_id in ground_truth_ids:\n",
    "    query = f\"\"\" SELECT concat(title,'. ',text) as text FROM `ingka-feed-student-dev.RR.RatingsReviews` AS rr\n",
    "                INNER JOIN `ingka-feed-student-dev.RR.product_categories` AS pc \n",
    "                ON rr.art_id = SPLIT(pc.global_id, ',')[SAFE_OFFSET(1)] \n",
    "                WHERE country_code = 'us' and PRODUCT_AREA = 'Open storage' and art_id = '{art_id}'\n",
    "                ORDER BY inserted_on DESC \"\"\"\n",
    "\n",
    "    query_job = client.query(query)\n",
    "\n",
    "    article_reviews = []\n",
    "\n",
    "    for review in query_job:\n",
    "         article_reviews.append(review.text)\n",
    "\n",
    "    all_reviews.append(article_reviews)\n",
    "len(all_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4df839bd-b19b-4e53-b74f-3fd87265b455",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import download\n",
    "download('punkt')\n",
    "\n",
    "def count_tokens_in_reviews(review_list):\n",
    "    total_tokens = 0\n",
    "    for review in review_list:\n",
    "        total_tokens += len(word_tokenize(review))\n",
    "    return total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab4efa9b-96fd-4e31-b920-afa820cef7ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def categorize_reviews_by_token_count(reviews, max_tokens):\n",
    "    above_limit = []\n",
    "    below_limit = []\n",
    "\n",
    "    for review_group in reviews:\n",
    "        token_count = count_tokens_in_reviews(review_group)\n",
    "        if token_count > max_tokens:\n",
    "            above_limit.append(review_group)\n",
    "        else:\n",
    "            below_limit.append(review_group)\n",
    "    \n",
    "    return below_limit, above_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82516bfc-c48e-43d5-a265-d5ad3788ea13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Products with <= 5000 tokens:\n",
      "5\n",
      "Products with > 5000 tokens:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Applying the function\n",
    "below_limit, above_limit = categorize_reviews_by_token_count(all_reviews, max_tokens=5000)\n",
    "\n",
    "print(\"Products with <= 5000 tokens:\")\n",
    "print(len(below_limit))\n",
    "\n",
    "print(\"Products with > 5000 tokens:\")\n",
    "print(len(above_limit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb3f77ec-6216-4ed2-96f4-9adce99d3dc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.31.0.dev0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (24.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.3.0)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.23.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4686b796f2cd40bfb3e608e012b2c337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "access_token = \"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\"\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    token=access_token,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4bffedc-d6ce-40f4-a00c-bcf5398bfc18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "answers = []\n",
    "\n",
    "for reviews in all_reviews:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful chatbot who only answer with a comma-separated list of the requested topics and no additional text\"},\n",
    "        {\"role\": \"user\", \"content\": 'From these reviews, generate maximum 15 non-redundant topics. Topics should be 1 word maximum, can be 2 or 3 if necessary. The topics should be about qualities and characteristics of the products (ex: quality, price, …) and not names of objects (like Books, shelves, …). The topics should be names (ex: not durable but durability). Answer only with a comma-separated list of the topics you identify. Reviews: \"Perfect Simple TV Stand. I actually went in to buy something different, but when I saw the possibility of changing the orientation of this bookshelf and combining with a stand (maybe not even necessary but I think it enhances the appearance), I bought this instead. It seems sturdy and durable, looks good, I’m happy with my purchase. I put a couple of Fossta bins in mine but there are many other options for the storage bays.\",\"Good quality. Good looking and quality\",\"TV Stand With Base. A Simple, clean and light weight unit when cocmbined with the metal base works well as a tv stand in my case a 55\" TV. I\\'ll probably get the black baskets which fit perfectly into this or craft something simple to cover the back. I was worried that the round bottom of the legs would not be secure into the sqare legs of the base but they seem to fit without movement. But be aware that the top is not secured in any way- meaning you can lift this kallax right up out of the base. Of course the weight of the tv will prevent that from occurring but ikea should have engineered a way to secure theKallax base to this Kallax unit.\",\"IKEA perfection. IKEA perfection\"\t,\"Sturdy, good quality and minimalist, Love it!. This media console is just what I needed! It simple, sturdy and minimalist. It was easy to built. Thanks to the visual instructions! Very good quality and it\\'s a minimalist piece. It adds to the TV room without interfering with the rest of the furniture but adding weigh to it, which was necessary. It is also useful because I store a blanket in one of the shelves, my sleepers in another one and tv stuff...\",\t\"Nice piece. I like it.\",\"Simple and elegant. Simple and elegant\".'},\n",
    "        {\"role\": \"assistant\", \"content\": \"Durability, Simplicity, Sturdiness, Quality, Weight, Minimalism, Appearance, Security, Ease of Assembly, Flexibility\"},\n",
    "        {\"role\": \"user\", \"content\": f'From these reviews, generate maximum 15 non-redundant topics. Topics should be 1 word maximum, can be 2 or 3 if necessary. The topics should be about qualities and characteristics of the products (ex: quality, price, …) and not names of objects (like Books, shelves, …). The topics should be names (ex: not durable but durability). Answer only with a comma-separated list of the topics you identify. Reviews: {reviews}.'},\n",
    "    ]\n",
    "\n",
    "    prompt = pipeline.tokenizer.apply_chat_template(\n",
    "            messages, \n",
    "            tokenize=False, \n",
    "            add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    terminators = [\n",
    "        pipeline.tokenizer.eos_token_id,\n",
    "        pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "\n",
    "    outputs = pipeline(\n",
    "    prompt,\n",
    "    max_new_tokens=100,\n",
    "    eos_token_id=terminators,    \n",
    "    pad_token_id=pipeline.tokenizer.eos_token_id,\n",
    "    do_sample=True,\n",
    "    temperature=0.3,\n",
    "    top_p=0.9,\n",
    "    )\n",
    "\n",
    "    answer=outputs[0][\"generated_text\"][len(prompt):]\n",
    "    answers.append(answer)\n",
    "    if (answers.index(answer) + 1) % 10 == 0: \n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(f\"{answers.index(answer) + 1}th file completed in {elapsed_time} seconds.\")\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a37444e9-a1d0-45b3-9d00-180f86f44ed9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file \"5Shot_Examples.csv\" has been written successfully.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "filename = '5Shot_Examples.csv'\n",
    "\n",
    "# Writing to the csv file\n",
    "with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    # Creating a csv writer object with quoting set to quote all fields\n",
    "    csvwriter = csv.writer(csvfile, delimiter=';')\n",
    "    \n",
    "    # Writing the columns\n",
    "    csvwriter.writerow(['ArticleID', 'Topics'])\n",
    "    \n",
    "    # Writing the data\n",
    "    for article, answer in zip(ground_truth_ids, answers):\n",
    "        csvwriter.writerow([article, answer])\n",
    "\n",
    "print(f'CSV file \"{filename}\" has been written successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edb2487-ff00-4f81-8a67-c8e3ef352d54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m120"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
