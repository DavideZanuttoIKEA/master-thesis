{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c3b1f61-bb89-42f5-a913-9f11b72d7a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Art Ids: ['70301542', '19294535', '89442655', '90301555', '69329387', '79442689', '39442672', '09442678', '90510865', '89278259', '29278304', '80401292', '29442615', '69442680', '50454507', '19189030', '59442685', '49442676', '70538846', '19442654', '29481701', '40501892', '49189203', '80487813', '19442692', '59189472', '79278250', '59294557', '99017445', '79442694']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path=\"csv/GroundTruthV2.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path, sep=\";\")\n",
    "\n",
    "# Extract columns into separate arrays\n",
    "art_ids = df.iloc[:, 0].tolist()  # First column\n",
    "topics = df.iloc[:, 1].tolist()  # Second column\n",
    "\n",
    "art_ids = [str(number).zfill(8) for number in art_ids] #Add 0 padding for articleIDs\n",
    "\n",
    "# Print the arrays to verify\n",
    "print(\"Art Ids:\", art_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d085f2c5-b09e-4452-9f03-a4546861807f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "client = bigquery.Client()\n",
    "\n",
    "all_reviews = []\n",
    "\n",
    "for art_id in art_ids:\n",
    "    query = f\"\"\"SELECT concat(title,'. ',text) as text FROM `ingka-feed-student-dev.RR.RatingsReviews` AS rr\n",
    "                INNER JOIN `ingka-feed-student-dev.RR.product_categories` AS pc \n",
    "                ON rr.art_id = SPLIT(pc.global_id, ',')[SAFE_OFFSET(1)] \n",
    "                WHERE country_code = 'us' and PRODUCT_AREA = 'Open storage' and art_id = '{art_id}'\n",
    "                ORDER BY inserted_on DESC \"\"\"\n",
    "\n",
    "    query_job = client.query(query)\n",
    "\n",
    "    article_reviews = []\n",
    "\n",
    "    for review in query_job:\n",
    "         article_reviews.append(review.text)\n",
    "\n",
    "    all_reviews.append(article_reviews)\n",
    "len(all_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2370e640-1592-4f76-853f-75a98ebd2054",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import download\n",
    "download('punkt')\n",
    "\n",
    "def count_tokens_in_reviews(review_list):\n",
    "    total_tokens = 0\n",
    "    for review in review_list:\n",
    "        total_tokens += len(word_tokenize(review))\n",
    "    return total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12de73e3-b380-42f5-851c-46750b930750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_reviews_by_token_count(reviews, max_tokens):\n",
    "    above_limit = []\n",
    "    below_limit = []\n",
    "    index_above = []\n",
    "    \n",
    "    for review_group in reviews:\n",
    "        token_count = count_tokens_in_reviews(review_group)\n",
    "        if token_count > max_tokens:\n",
    "            above_limit.append(review_group)\n",
    "            index_above.append(all_reviews.index(review_group))\n",
    "        else:\n",
    "            below_limit.append(review_group)\n",
    "    \n",
    "    return below_limit, above_limit, index_above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba7afff1-052a-4b3b-88d0-250d30da0963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Products with <= 5000 tokens:\n",
      "29\n",
      "Products with > 5000 tokens:\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Applying the function\n",
    "below_limit, above_limit, index_above = categorize_reviews_by_token_count(all_reviews, max_tokens=5000)\n",
    "\n",
    "print(\"Products with <= 5000 tokens:\")\n",
    "print(len(below_limit))\n",
    "\n",
    "print(\"Products with > 5000 tokens:\")\n",
    "print(len(above_limit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0aac7f9d-6b07-43ef-94f7-a7c5d9eb03be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('selected_reviews.json', mode='r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "    above_limit_final = data[\"reviews\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a323e9cb-9acc-4d69-b047-dfeb9fca132a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['70301542',\n",
       " '19294535',\n",
       " '89442655',\n",
       " '90301555',\n",
       " '69329387',\n",
       " '79442689',\n",
       " '39442672',\n",
       " '09442678',\n",
       " '90510865',\n",
       " '89278259',\n",
       " '29278304',\n",
       " '80401292',\n",
       " '29442615',\n",
       " '69442680',\n",
       " '50454507',\n",
       " '19189030',\n",
       " '59442685',\n",
       " '49442676',\n",
       " '70538846',\n",
       " '19442654',\n",
       " '29481701',\n",
       " '40501892',\n",
       " '49189203',\n",
       " '80487813',\n",
       " '19442692',\n",
       " '59189472',\n",
       " '79278250',\n",
       " '59294557',\n",
       " '99017445',\n",
       " '79442694']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements_to_move = [art_ids[i] for i in index_above]\n",
    "    \n",
    "remaining_elements = [art_id for i, art_id in enumerate(art_ids) if i not in index_above]\n",
    "\n",
    "art_ids = elements_to_move + remaining_elements\n",
    "\n",
    "art_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "532284f2-4a86-490a-abd6-4e972f922ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_reviews = above_limit_final + below_limit\n",
    "len(all_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "878be44b-b1ee-4ed2-abde-aa971b070735",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Nice and sturdy, Great storage space, easily assemble, loose construction,'], [], [], ['several sizes, works well, sturdy, great storage space, great value, easy to assemble, looks good, Arrived damaged,'], [\"Frustrating item, latch doesn't work, easy to clean underneath, permanent room feature, Architectural Digest look, crooked drawers,\"], ['looks good, optional drawers, would recommend Kallax products, easy assembly,'], [], ['looks wonderful, many options,'], [], ['great storage, Unable to purchase,'], ['Easy to transport, Kallax series, Installing doors and drawers, Durable, Excellent storage solution, Looks great, Great product, affordable, easy assembly,'], ['great use of space, well-built, Handy for craft supplies, for kallax shelves, holds wine bottles, Easy to assemble,'], ['comes together nicely, addition of legs,'], ['Built an entire wall, decent appearance, heavy-duty c-clamps, clear directions for base installation, several different colors, Works great for storage, Old school stereo console, perfect grey and light wood mix,'], ['Easy to assemble, works well, Decent rolling shelf, Oak appearance, Product was marked incorrectly,'], [], ['easy to assemble, well made, black base stand, Book shelf, sometimes out of stock, damaged side, Kallax for record albums,'], ['good value, functional, added inserts, easy assembly, can raise up on legs, storage below,'], ['easy assembly, Well designed, Good price, below windows, can hold large TV and soundbar,'], ['(No additional characteristics or sentiments given in the sentence), Great shelve,'], ['Functional, easy installation, killer line, wall anchors,'], ['well made, Looks great, Kallax with elegant legs, Simple stand, provides height, Affordable addition, Easy to build, makes bookcase more functional, Not fit old Kallax shelf,'], ['holds a lot, incompatible with glass window, tricky assembly, plastic attachment grooves,'], ['Ample shelf space, easy assembly,'], ['Worked perfectly, Easy to assemble, storage closet,'], [], ['Great for organizing, issue with doors,'], ['Thoughtful design, Great price,'], ['Great product, Excellent storage, provides shelving for small items, sturdy, love them all, Television stand, no clear sentiment expressed in sentence., looks great, easy assembly,'], ['provides storage, easy assembly,']]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('csv/core_keyphrases_hierarchical.csv')  \n",
    "\n",
    "core_keyphrases = []\n",
    "for art_id in art_ids:\n",
    "    keyphrases = data[data['art_id'] == int(art_id)]['core_keyphrases'].tolist()\n",
    "    core_keyphrases.append(keyphrases)\n",
    "\n",
    "print(core_keyphrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "888d34f4-914a-4f12-9811-74725e6c104a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Art Ids: ['80508504', '49398678', '09294526', '10538849', '29278262']\n",
      "Topics: ['Quality, Price, Availability, Practicality, Style, Versatilite, Ease of Assembly, Screw', 'Quality, Ease of Assembly, Delivery', 'Quality, Size, Sturdiness, Space, Height, Ease of Assembly', 'Quality, Ease of Assembly, Instructions, Appearance, Material, Price, Design, Sturdiness', 'Quality, Ease of Assembly, Appearance, Versatility, Limitations, Value, Functionality, Sturdiness']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path=\"5Shot_Examples.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path, sep=\";\")\n",
    "\n",
    "# Extract columns into separate arrays\n",
    "art_ids_5shot = df.iloc[:, 0].tolist()  # First column\n",
    "topics_5shot = df.iloc[:, 1].tolist()  # Second column\n",
    "\n",
    "art_ids_5shot = [str(number).zfill(8) for number in art_ids_5shot] #Add 0 padding for articleIDs\n",
    "\n",
    "# Print the arrays to verify\n",
    "print(\"Art Ids:\", art_ids_5shot)\n",
    "print(\"Topics:\", topics_5shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac0bce4c-019c-40da-ace4-fc0d8353d1fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Good product, Kallax shelf unit, easy installation, limited availability, new price increase, stripped screws, white interior, wish for right/left options,'], ['easy to assemble, Exceptional pieces of storage, good experience,'], [\"Perfect storage solution, didn't always line up right,\"], ['nice material, include wall anchor kit, Clear installation instructions, pleasing shelf unit, carpenter friend found it challenging,'], ['Sturdy, Organization, Happy about product, Easy to find, junk doors, Easy assembly, good looking, slightly different,']]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('csv/core_keyphrases_hierarchical.csv')  \n",
    "\n",
    "core_keyphrases_5shot = []\n",
    "for art_id in art_ids_5shot:\n",
    "    keyphrases = data[data['art_id'] == int(art_id)]['core_keyphrases'].tolist()\n",
    "    core_keyphrases_5shot.append(keyphrases)\n",
    "\n",
    "print(core_keyphrases_5shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77f1936d-a3bd-45ce-a266-f31f1ad93ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "client = bigquery.Client()\n",
    "\n",
    "reviews_5shot = []\n",
    "\n",
    "for art_id in art_ids_5shot:\n",
    "    query = f\"\"\" SELECT concat(title,'. ',text) as text FROM `ingka-feed-student-dev.RR.RatingsReviews` AS rr\n",
    "                INNER JOIN `ingka-feed-student-dev.RR.product_categories` AS pc \n",
    "                ON rr.art_id = SPLIT(pc.global_id, ',')[SAFE_OFFSET(1)] \n",
    "                WHERE country_code = 'us' and PRODUCT_AREA = 'Open storage' and art_id = '{art_id}'\n",
    "                ORDER BY inserted_on DESC \"\"\"\n",
    "\n",
    "    query_job = client.query(query)\n",
    "\n",
    "    article_reviews = []\n",
    "\n",
    "    for review in query_job:\n",
    "         article_reviews.append(review.text)\n",
    "\n",
    "    reviews_5shot.append(article_reviews)\n",
    "len(reviews_5shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f79e49cb-9bf2-4d9a-9c8a-77b91fade4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.31.0.dev0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (24.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.3.0)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.23.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a70ddfb6814503a25f074e60f6e068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "access_token = \"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\"\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    token=access_token,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b96a990-21f1-43d7-809c-c6ee62d20b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10th file completed in 27.975313425064087 seconds.\n",
      "20th file completed in 52.160367488861084 seconds.\n",
      "30th file completed in 76.06164073944092 seconds.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "answers = []\n",
    "\n",
    "for reviews, core in zip(all_reviews, core_keyphrases):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful chatbot who only answer with a comma-separated list of the requested topics and no additional text\"},\n",
    "        {\"role\": \"user\", \"content\": f'From these reviews and core keyphrases, generate maximum 8 non-redundant topics. Topics should be 1 word maximum, can be 2 or 3 if necessary. The topics should be about qualities and characteristics of the products (ex: quality, price, …). The topics should be nouns (ex: not durable but durability). Answer only with a comma-separated list of the topics you identify. Reviews: {reviews_5shot[0]}. Keyphrases: {core_keyphrases_5shot[0]}.'},        \n",
    "        {\"role\": \"assistant\", \"content\":f'{topics_5shot[0]}'},\n",
    "        {\"role\": \"user\", \"content\": f'From these reviews and core keyphrases, generate maximum 8 non-redundant topics. Topics should be 1 word maximum, can be 2 or 3 if necessary. The topics should be about qualities and characteristics of the products (ex: quality, price, …). The topics should be nouns (ex: not durable but durability). Answer only with a comma-separated list of the topics you identify. Reviews: {reviews_5shot[1]}. Keyphrases: {core_keyphrases_5shot[1]}.'},        \n",
    "        {\"role\": \"assistant\", \"content\":f'{topics_5shot[1]}'},\n",
    "        {\"role\": \"user\", \"content\": f'From these reviews and core keyphrases, generate maximum 8 non-redundant topics. Topics should be 1 word maximum, can be 2 or 3 if necessary. The topics should be about qualities and characteristics of the products (ex: quality, price, …). The topics should be nouns (ex: not durable but durability). Answer only with a comma-separated list of the topics you identify. Reviews: {reviews_5shot[2]}. Keyphrases: {core_keyphrases_5shot[2]}.'},        \n",
    "        {\"role\": \"assistant\", \"content\":f'{topics_5shot[2]}'},\n",
    "        {\"role\": \"user\", \"content\": f'From these reviews and core keyphrases, generate maximum 8 non-redundant topics. Topics should be 1 word maximum, can be 2 or 3 if necessary. The topics should be about qualities and characteristics of the products (ex: quality, price, …). The topics should be nouns (ex: not durable but durability). Answer only with a comma-separated list of the topics you identify. Reviews: {reviews_5shot[3]}. Keyphrases: {core_keyphrases_5shot[3]}.'},        \n",
    "        {\"role\": \"assistant\", \"content\":f'{topics_5shot[3]}'},\n",
    "        {\"role\": \"user\", \"content\": f'From these reviews and core keyphrases, generate maximum 8 non-redundant topics. Topics should be 1 word maximum, can be 2 or 3 if necessary. The topics should be about qualities and characteristics of the products (ex: quality, price, …). The topics should be nouns (ex: not durable but durability). Answer only with a comma-separated list of the topics you identify. Reviews: {reviews_5shot[4]}. Keyphrases: {core_keyphrases_5shot[4]}.'},        \n",
    "        {\"role\": \"assistant\", \"content\":f'{topics_5shot[4]}'},\n",
    "        {\"role\": \"user\", \"content\": f'From these reviews and core keyphrases, generate maximum 8 non-redundant topics. Topics should be 1 word maximum, can be 2 or 3 if necessary. The topics should be about qualities and characteristics of the products (ex: quality, price, …). The topics should be nouns (ex: not durable but durability). Answer only with a comma-separated list of the topics you identify. Reviews: {reviews}. Keyphrases: {core}.'},        \n",
    "    ]\n",
    "\n",
    "    prompt = pipeline.tokenizer.apply_chat_template(\n",
    "            messages, \n",
    "            tokenize=False, \n",
    "            add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    terminators = [\n",
    "        pipeline.tokenizer.eos_token_id,\n",
    "        pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "\n",
    "    outputs = pipeline(\n",
    "    prompt,\n",
    "    max_new_tokens=50,\n",
    "    eos_token_id=terminators,    \n",
    "    pad_token_id=pipeline.tokenizer.eos_token_id,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    "    )\n",
    "\n",
    "    answer=outputs[0][\"generated_text\"][len(prompt):]\n",
    "    answers.append(answer)\n",
    "    if (answers.index(answer) + 1) % 10 == 0: \n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(f\"{answers.index(answer) + 1}th file completed in {elapsed_time} seconds.\")\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc32d85d-369e-4b01-8f94-6897b4a1a81c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv/GTv2/5ShotLlama3ReviewsKeyphrasesHierarchical.csv written with limited answer length!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "filename = \"csv/GTv2/5ShotLlama3ReviewsKeyphrasesHierarchical.csv\"\n",
    "\n",
    "def process_answer(answer, max_words=8):\n",
    "    return ','.join(answer.split(',')[:max_words])\n",
    "\n",
    "def write_csv(filename, art_ids, answers, max_words=8):\n",
    "  \n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        # Creating a csv writer object with quoting set to quote all fields\n",
    "        csvwriter = csv.writer(csvfile, delimiter=';')\n",
    "\n",
    "        # Writing the columns\n",
    "        csvwriter.writerow(['ArticleID', 'Topics'])\n",
    "\n",
    "        # Writing the data with processed answers\n",
    "        for article, answer in zip(art_ids, answers):\n",
    "            processed_answer = process_answer(answer, max_words)\n",
    "            csvwriter.writerow([article, processed_answer])\n",
    "\n",
    "write_csv(filename, art_ids, answers)\n",
    "print(f\"{filename} written with limited answer length!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd340ab-45b3-48fd-b2dc-1cb9bd0d873d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m120"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
