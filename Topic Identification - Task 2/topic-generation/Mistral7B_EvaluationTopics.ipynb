{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c3b1f61-bb89-42f5-a913-9f11b72d7a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Art Ids: ['19294535', '29294554', '90301555', '69329387', '79442689', '39442672', '09442678', '90510865', '89278259', '29278304', '80401292', '29442615', '69442680', '50454507', '19189030', '59442685', '49442676', '70538846', '19442654', '29481701', '40501892', '49189203', '80487813', '19442692', '59189472', '70301542', '79278250', '59294557', '99017445', '79442694']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path=\"csv/GroundTruth_topics_llama3.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path, sep=\";\")\n",
    "\n",
    "# Extract columns into separate arrays\n",
    "art_ids = df.iloc[:, 0].tolist()  # First column\n",
    "topics = df.iloc[:, 1].tolist()  # Second column\n",
    "\n",
    "art_ids = [str(number).zfill(8) for number in art_ids] #Add 0 padding for articleIDs\n",
    "\n",
    "# Print the arrays to verify\n",
    "print(\"Art Ids:\", art_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d085f2c5-b09e-4452-9f03-a4546861807f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "client = bigquery.Client()\n",
    "\n",
    "all_reviews = []\n",
    "\n",
    "for art_id in art_ids:\n",
    "    query = f\"\"\" SELECT concat(title,'. ',text) as text FROM `ingka-feed-student-dev.RR.RatingsReviews` AS rr\n",
    "                INNER JOIN `ingka-feed-student-dev.RR.product_categories` AS pc \n",
    "                ON rr.art_id = SPLIT(pc.global_id, ',')[SAFE_OFFSET(1)] \n",
    "                WHERE country_code = 'us' and PRODUCT_AREA = 'Open storage' and art_id = '{art_id}'\n",
    "                ORDER BY inserted_on DESC \"\"\"\n",
    "\n",
    "    query_job = client.query(query)\n",
    "\n",
    "    article_reviews = []\n",
    "\n",
    "    for review in query_job:\n",
    "         article_reviews.append(review.text)\n",
    "\n",
    "    all_reviews.append(article_reviews)\n",
    "len(all_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2370e640-1592-4f76-853f-75a98ebd2054",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import download\n",
    "download('punkt')\n",
    "\n",
    "def count_tokens_in_reviews(review_list):\n",
    "    total_tokens = 0\n",
    "    for review in review_list:\n",
    "        total_tokens += len(word_tokenize(review))\n",
    "    return total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12de73e3-b380-42f5-851c-46750b930750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_reviews_by_token_count(reviews, max_tokens):\n",
    "    above_limit = []\n",
    "    below_limit = []\n",
    "    index_above = []\n",
    "    \n",
    "    for review_group in reviews:\n",
    "        token_count = count_tokens_in_reviews(review_group)\n",
    "        if token_count > max_tokens:\n",
    "            above_limit.append(review_group)\n",
    "            index_above.append(all_reviews.index(review_group))\n",
    "        else:\n",
    "            below_limit.append(review_group)\n",
    "    \n",
    "    return below_limit, above_limit, index_above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba7afff1-052a-4b3b-88d0-250d30da0963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Products with <= 5000 tokens:\n",
      "29\n",
      "Products with > 5000 tokens:\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Applying the function\n",
    "below_limit, above_limit, index_above = categorize_reviews_by_token_count(all_reviews, max_tokens=5000)\n",
    "\n",
    "print(\"Products with <= 5000 tokens:\")\n",
    "print(len(below_limit))\n",
    "\n",
    "print(\"Products with > 5000 tokens:\")\n",
    "print(len(above_limit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0aac7f9d-6b07-43ef-94f7-a7c5d9eb03be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('selected_reviews.json', mode='r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "    above_limit_final = data[\"reviews\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a323e9cb-9acc-4d69-b047-dfeb9fca132a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['70301542',\n",
       " '19294535',\n",
       " '29294554',\n",
       " '90301555',\n",
       " '69329387',\n",
       " '79442689',\n",
       " '39442672',\n",
       " '09442678',\n",
       " '90510865',\n",
       " '89278259',\n",
       " '29278304',\n",
       " '80401292',\n",
       " '29442615',\n",
       " '69442680',\n",
       " '50454507',\n",
       " '19189030',\n",
       " '59442685',\n",
       " '49442676',\n",
       " '70538846',\n",
       " '19442654',\n",
       " '29481701',\n",
       " '40501892',\n",
       " '49189203',\n",
       " '80487813',\n",
       " '19442692',\n",
       " '59189472',\n",
       " '79278250',\n",
       " '59294557',\n",
       " '99017445',\n",
       " '79442694']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements_to_move = [art_ids[i] for i in index_above]\n",
    "    \n",
    "remaining_elements = [art_id for i, art_id in enumerate(art_ids) if i not in index_above]\n",
    "\n",
    "art_ids = elements_to_move + remaining_elements\n",
    "\n",
    "art_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "532284f2-4a86-490a-abd6-4e972f922ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_reviews = above_limit_final + below_limit\n",
    "len(all_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "888d34f4-914a-4f12-9811-74725e6c104a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Art Ids: ['80508504', '49398678', '09294526', '10538849', '29278262']\n",
      "Topics: ['Quality, Price, Availability, Practicality, Style, Versatilite, Ease of Assembly, Screw', 'Quality, Ease of Assembly, Delivery', 'Quality, Size, Sturdiness, Space, Height, Ease of Assembly', 'Quality, Ease of Assembly, Instructions, Appearance, Material, Price, Design, Sturdiness', 'Quality, Ease of Assembly, Appearance, Versatility, Limitations, Value, Functionality, Sturdiness']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path=\"5Shot_Examples.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path, sep=\";\")\n",
    "\n",
    "# Extract columns into separate arrays\n",
    "art_ids_5shot = df.iloc[:, 0].tolist()  # First column\n",
    "topics_5shot = df.iloc[:, 1].tolist()  # Second column\n",
    "\n",
    "art_ids_5shot = [str(number).zfill(8) for number in art_ids_5shot] #Add 0 padding for articleIDs\n",
    "\n",
    "# Print the arrays to verify\n",
    "print(\"Art Ids:\", art_ids_5shot)\n",
    "print(\"Topics:\", topics_5shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77f1936d-a3bd-45ce-a266-f31f1ad93ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "client = bigquery.Client()\n",
    "\n",
    "reviews_5shot = []\n",
    "\n",
    "for art_id in art_ids_5shot:\n",
    "    query = f\"\"\" SELECT concat(title,'. ',text) as text FROM `ingka-feed-student-dev.RR.RatingsReviews` AS rr\n",
    "                INNER JOIN `ingka-feed-student-dev.RR.product_categories` AS pc \n",
    "                ON rr.art_id = SPLIT(pc.global_id, ',')[SAFE_OFFSET(1)] \n",
    "                WHERE country_code = 'us' and PRODUCT_AREA = 'Open storage' and art_id = '{art_id}'\n",
    "                ORDER BY inserted_on DESC \"\"\"\n",
    "\n",
    "    query_job = client.query(query)\n",
    "\n",
    "    article_reviews = []\n",
    "\n",
    "    for review in query_job:\n",
    "         article_reviews.append(review.text)\n",
    "\n",
    "    reviews_5shot.append(article_reviews)\n",
    "len(reviews_5shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdc60149-7a8f-44a9-b003-90c5cc6834e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U bitsandbytes\n",
    "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
    "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
    "!pip install -q -U git+https://github.com/huggingface/accelerate.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f79e49cb-9bf2-4d9a-9c8a-77b91fade4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['bnb_8bit_use_double_quant', 'bnb_8bit_quant_type', 'bnb_8bit_compute_dtype']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "886eb55fddb648289691611522e8a776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "device = \"cuda\" # the device to load the model onto\n",
    "access_token = \"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\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    bnb_8bit_use_double_quant=True,\n",
    "    bnb_8bit_quant_type=\"nf4\",\n",
    "    bnb_8bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\", quantization_config=bnb_config, device_map=\"auto\", token=access_token)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\", token=access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b96a990-21f1-43d7-809c-c6ee62d20b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Organizing, Sturdy, Easy assembly, Functional, Space-saving, Modern, Value, Quality.\n",
      "Organization, Appearance, Space\n",
      " Love, Want, Satisfaction.\n",
      "Quality, Ease of Assembly, Durability, Versatility, Aesthetics, Functionality, Value, Sturdiness.\n",
      " Appearance, Alignment, Durability, Ease of Assembly, Functionality, Instructions, Sturdiness, Value\n",
      " Quality, Ease of Assembly, Value, Appearance, Sturdiness, Size, Functionality, Tape (if removing it is identified as a challenge in the reviews)\n",
      " Storage, Cookbooks.\n",
      "Ease of assembly, Versatility, Appearance, Functionality, Durability, Options, Size, Value.\n",
      " Quality, Satisfaction, Value.\n",
      " Quality, Ease of Assembly, Economy, Size, Storage, Durability, Repairability, Organization\n",
      "10th file completed in 118.67907667160034 seconds.\n",
      " Sturdy, Easy assembly, Space-saving, Versatile, Quality, Appealing, Value, Durable\n",
      "\n",
      "Note: Some of the reviews mention specific products such as \"Kallax\" and \"cube units\", but the topics identified are general qualities and characteristics applicable to various storage products.\n",
      " Quality, Value, Size, Ease of Assembly, Functionality, Versatility, Sturdiness, Organization, Space, Wine, Craft Supplies, Shoes, Scraps, Accessories, Instructions, Appearance.\n",
      "Quality, Ease of Assembly, Appearance, Affordability, Durability, Functionality, Patience, Legs.\n",
      "Ease of Assembly, Quality, Functionality, Storage, Appearance, Durability, LP storage, Value.\n",
      "Quality, Rolling, Easy Assembly, Appearance, Storage, Value, Functionality, Durability, Adjustable, Oak, Portable, Wheels, Lockable.\n",
      " Decor, Appearance, Quality, Fit, (Sewing Room), Satisfaction\n",
      " Quality, Ease of Assembly, Construction, Sturdiness, Appearance, Functionality, Options, Availability\n",
      " Quality, Ease of Assembly, Value, Functionality, Aesthetics, Size, Versatility, Durability, Instructions, Sturdiness, Organization, Customizable, Storage, Adjustability.\n",
      " Quality, Ease of Assembly, Price, Height, Sturdiness, Design, Look, Size.\n",
      " Ease of Assembly, Appearance\n",
      "20th file completed in 261.06102180480957 seconds.\n",
      "Versatility, Functionality, Durability, Ease of Assembly, Sturdiness, Construction, Mounting, Hardware.\n",
      "Quality, Ease of Assembly, Value, Sturdiness, Height, Lift, Appearance, versatility, Functionality, Solution, Upgrade.\n",
      " Assembly, Quality, Price, Appearance, Compatibility, Resistance, Damage, Inconvenience.\n",
      " Ease of assembly, Appearance, Functionality, Sturdiness, Value, organized, Space, Cute, Lightweight, Adjustable, Clean lines.\n",
      "Easy, Sturdy, Perfect, Storage, Expected, Assemble.\n",
      " Appearance, Satisfaction.\n",
      "Easy assembly, Space saving, Functional, Perfect, Organizing, Sturdy, Cubies, Finished look.\n",
      " Price, Easy assembly, Attractive, Sturdy, Thoughtful design\n",
      "Quality, Functionality, Ease of Assembly, Appearance, Versatility, Value, Sturdiness, Customer Service.\n",
      "Storage, Quality, Versatility, Appearance, Value, Assembly, Functionality, Height.\n",
      "30th file completed in 349.80653834342957 seconds.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "device = \"cuda\"\n",
    "answers = []\n",
    "pre_text = 2125 + 448 + len(str(topics_5shot[0])) + len(str(reviews_5shot[0])) + len(str(topics_5shot[1])) + len(str(reviews_5shot[1])) + len(str(topics_5shot[2])) + len(str(reviews_5shot[2])) + len(str(topics_5shot[3])) + len(str(reviews_5shot[3])) + len(str(topics_5shot[4])) + len(str(reviews_5shot[4]))\n",
    "eos_token_id = tokenizer.convert_tokens_to_ids('.')\n",
    "eos_token_id_additional = tokenizer.convert_tokens_to_ids('<')\n",
    "\n",
    "for reviews in all_reviews:\n",
    "    lenrev = len(str(reviews))\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": f'From these reviews, generate maximum 8 non-redundant topics. Topics should be 1 word maximum, can be 2 or 3 if necessary. The topics should be about qualities and characteristics of the products (ex: quality, price, …) and not names of objects (like Books, shelves, …). The topics should be names (ex: not durable but durability). Answer only with a comma-separated list of the topics you identify. Reviews: {reviews_5shot[0]}.'},        \n",
    "        {\"role\": \"assistant\", \"content\":f'{topics_5shot[0]}'},\n",
    "        {\"role\": \"user\", \"content\": f'From these reviews, generate maximum 8 non-redundant topics. Topics should be 1 word maximum, can be 2 or 3 if necessary. The topics should be about qualities and characteristics of the products (ex: quality, price, …) and not names of objects (like Books, shelves, …). The topics should be names (ex: not durable but durability). Answer only with a comma-separated list of the topics you identify. Reviews: {reviews_5shot[1]}.'},        \n",
    "        {\"role\": \"assistant\", \"content\":f'{topics_5shot[1]}'},\n",
    "        {\"role\": \"user\", \"content\": f'From these reviews, generate maximum 8 non-redundant topics. Topics should be 1 word maximum, can be 2 or 3 if necessary. The topics should be about qualities and characteristics of the products (ex: quality, price, …) and not names of objects (like Books, shelves, …). The topics should be names (ex: not durable but durability). Answer only with a comma-separated list of the topics you identify. Reviews: {reviews_5shot[2]}.'},        \n",
    "        {\"role\": \"assistant\", \"content\":f'{topics_5shot[2]}'},\n",
    "        {\"role\": \"user\", \"content\": f'From these reviews, generate maximum 8 non-redundant topics. Topics should be 1 word maximum, can be 2 or 3 if necessary. The topics should be about qualities and characteristics of the products (ex: quality, price, …) and not names of objects (like Books, shelves, …). The topics should be names (ex: not durable but durability). Answer only with a comma-separated list of the topics you identify. Reviews: {reviews_5shot[3]}.'},        \n",
    "        {\"role\": \"assistant\", \"content\":f'{topics_5shot[3]}'},\n",
    "        {\"role\": \"user\", \"content\": f'From these reviews, generate maximum 8 non-redundant topics. Topics should be 1 word maximum, can be 2 or 3 if necessary. The topics should be about qualities and characteristics of the products (ex: quality, price, …) and not names of objects (like Books, shelves, …). The topics should be names (ex: not durable but durability). Answer only with a comma-separated list of the topics you identify. Reviews: {reviews_5shot[4]}.'},        \n",
    "        {\"role\": \"assistant\", \"content\":f'{topics_5shot[4]}'},\n",
    "        {\"role\": \"user\", \"content\": f'From these reviews, generate maximum 8 non-redundant topics. Topics should be 1 word maximum, can be 2 or 3 if necessary. The topics should be about qualities and characteristics of the products (ex: quality, price, …) and not names of objects (like Books, shelves, …). The topics should be names (ex: not durable but durability). Answer only with a comma-separated list of the topics you identify. Reviews: {reviews}.'},        \n",
    "    ]\n",
    "\n",
    "    encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
    "\n",
    "    model_inputs = encodeds.to(device)\n",
    "\n",
    "    generated_ids = model.generate(model_inputs, max_new_tokens=100, pad_token_id=eos_token_id, eos_token_id=eos_token_id, do_sample=True)\n",
    "    decoded = tokenizer.batch_decode(generated_ids)\n",
    "    answer = decoded[0]\n",
    "    answer = answer[pre_text+lenrev:]\n",
    "\n",
    "    if eos_token_id_additional != -1:\n",
    "        answer = answer.split('<')[0]\n",
    "        \n",
    "    print(answer)\n",
    "    answers.append(answer)\n",
    "    \n",
    "    if (answers.index(answer) + 1) % 10 == 0: \n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(f\"{answers.index(answer) + 1}th file completed in {elapsed_time} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc32d85d-369e-4b01-8f94-6897b4a1a81c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv/5ShotMistral7B_Topics.csv written with limited answer length!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "filename = \"csv/5ShotMistral7B_Topics.csv\"\n",
    "\n",
    "def process_answer(answer, max_words=8):\n",
    "    return ','.join(answer.split(',')[:max_words])\n",
    "\n",
    "def write_csv(filename, art_ids, answers, max_words=8):\n",
    "  \n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        # Creating a csv writer object with quoting set to quote all fields\n",
    "        csvwriter = csv.writer(csvfile, delimiter=';')\n",
    "\n",
    "        # Writing the columns\n",
    "        csvwriter.writerow(['ArticleID', 'Topics'])\n",
    "\n",
    "        # Writing the data with processed answers\n",
    "        for article, answer in zip(art_ids, answers):\n",
    "            processed_answer = process_answer(answer, max_words)\n",
    "            csvwriter.writerow([article, processed_answer])\n",
    "\n",
    "write_csv(filename, art_ids, answers)\n",
    "print(f\"{filename} written with limited answer length!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95095fbb-9a5a-4b56-bb92-b359e9dcc557",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m120"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
