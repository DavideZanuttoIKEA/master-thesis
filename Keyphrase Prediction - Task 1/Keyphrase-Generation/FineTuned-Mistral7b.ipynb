{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "286ecf8e-ed57-41dd-b97b-e040ab8de721",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /opt/conda/lib/python3.10/site-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in /opt/conda/lib/python3.10/site-packages (from openpyxl) (1.1.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Love Kallax. These are the best storage cubbies. I love them. Have them in my closets with the Drona boxes. My husband has some in his train room. They are a great staple to have.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install openpyxl\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('cleaned_evaluation_keyphrases_200US.xlsx')\n",
    "\n",
    "reviews = df.iloc[0:, 0].tolist()\n",
    "\n",
    "reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c2a6d5a-c68a-48d5-8b35-1cfc324899ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers\n",
      "  Cloning https://github.com/huggingface/transformers to /var/tmp/pip-req-build-wxw7n6ys\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /var/tmp/pip-req-build-wxw7n6ys\n",
      "  Resolved https://github.com/huggingface/transformers to commit 7c71b61daef4da1ec5dc41674718d895176af3be\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.42.0.dev0) (3.13.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers==4.42.0.dev0) (0.23.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.42.0.dev0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.42.0.dev0) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.42.0.dev0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.42.0.dev0) (2024.4.16)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.42.0.dev0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers==4.42.0.dev0) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.42.0.dev0) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.42.0.dev0) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.42.0.dev0) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.42.0.dev0) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.42.0.dev0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.42.0.dev0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.42.0.dev0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.42.0.dev0) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f0fc8aa-22de-4a6e-b0d8-9ee190bb858e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.32.0.dev0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (24.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.23.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.4)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5366f830a3234abe9a027a633f29510c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install accelerate\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,  # Mistral, same as before\n",
    "    quantization_config=bnb_config,  # Same quantization config as before\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    add_bos_token=True,\n",
    "    trust_remote_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a758043a-4137-46e0-95da-0e7e42ca0a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "model = PeftModel.from_pretrained(base_model, \"mistral-new-finetune-400/checkpoint-1000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81a4b562-b495-4ef5-93f2-4e22d436e5ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20th file completed in 187.16180872917175 seconds.\n",
      "40th file completed in 344.5018811225891 seconds.\n",
      "60th file completed in 489.290239572525 seconds.\n",
      "80th file completed in 668.565390586853 seconds.\n",
      "100th file completed in 849.5190889835358 seconds.\n",
      "120th file completed in 996.661926984787 seconds.\n",
      "140th file completed in 1145.7005922794342 seconds.\n",
      "160th file completed in 1364.4608039855957 seconds.\n",
      "180th file completed in 1527.9451723098755 seconds.\n",
      "200th file completed in 1685.4833595752716 seconds.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "device = \"cuda\"\n",
    "answers = []\n",
    "pre_text = 500 + 1221\n",
    "eos_token_id = tokenizer.convert_tokens_to_ids('.')\n",
    "eos_token_id_additional = tokenizer.convert_tokens_to_ids('<')\n",
    "\n",
    "for review in reviews: \n",
    "    review_len = len(review)\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": \"From this sentence: 'So soft. This mat is amazing, it’s so so soft to stand on, we are loving it' generate a keyphrase for each key characteristic of the product and classify the sentiment of each generated keyphrase between positive, negative or neutral. Don't give any explainations, the output should only be Keyphrase 1 - Sentiment 1, Keyphrase 2 - Sentiment 2, ...\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Soft to stand on - Positive, amazing mat - Positive\"},\n",
    "        {\"role\": \"user\", \"content\": \"From this sentence: 'Kallax. Nice clean look, sturdy and easy to put together' generate a keyphrase for each key characteristic of the product and classify the sentiment of each generated keyphrase between positive, negative or neutral. Don't give any explainations, the output should only be Keyphrase 1 - Sentiment 1, Keyphrase 2 - Sentiment 2, ...\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Clean look - Positive, sturdy - Positive, easy to assemble - Positive\"},\n",
    "        {\"role\": \"user\", \"content\": \"From this sentence: 'Great bookshelves. We bought 4 of these and made a library wall with them. Looks great and holds lots of books.' generate a keyphrase for each key characteristic of the product and classify the sentiment of each generated keyphrase between positive, negative or neutral. Don't give any explainations, the output should only be Keyphrase 1 - Sentiment 1, Keyphrase 2 - Sentiment 2, ...\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Great bookshelves - Positive, Looks great - Positive, made library wall - Neutral, capacious - Positive.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"From this sentence: '{review}' generate a keyphrase for each key characteristic of the product and classify the sentiment of each generated keyphrase between positive, negative or neutral. Don't give any explainations, the output should only be Keyphrase 1 - Sentiment 1, Keyphrase 2 - Sentiment 2, ...\"},\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
    "\n",
    "    model_inputs = encodeds.to(device)\n",
    "\n",
    "    generated_ids = model.generate(model_inputs, max_new_tokens=75, pad_token_id=eos_token_id, eos_token_id=eos_token_id, do_sample=True)\n",
    "    decoded = tokenizer.batch_decode(generated_ids)\n",
    "    \n",
    "    \n",
    "    answer = decoded[0][pre_text+review_len:]\n",
    "    \n",
    "    #if eos_token_id_additional != -1:\n",
    "    #    answer = answer.split('<')[0]\n",
    "        \n",
    "    answers.append(answer)\n",
    "\n",
    "    if (answers.index(answer) + 1) % 20 == 0: \n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(f\"{answers.index(answer) + 1}th file completed in {elapsed_time} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53d24921-7492-4331-a7a9-20e1e418a5c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reviews = [review.replace('\\n', ' ') for review in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73080708-a475-41fc-a4a8-72f748c4b1b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file \"Mistral-finetuned.csv\" has been written successfully.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "filename = 'Mistral-finetuned.csv'\n",
    "\n",
    "# Writing to the csv file\n",
    "with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    # Creating a csv writer object with quoting set to quote all fields\n",
    "    csvwriter = csv.writer(csvfile, delimiter=';')\n",
    "    \n",
    "    # Writing the columns\n",
    "    csvwriter.writerow(['Reviews', 'Keyphrases'])\n",
    "    \n",
    "    # Writing the data\n",
    "    for review, answer in zip(reviews, answers):\n",
    "        csvwriter.writerow([review, answer])\n",
    "\n",
    "print(f'CSV file \"{filename}\" has been written successfully.')"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m120"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
