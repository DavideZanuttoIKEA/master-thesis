{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c791a93-e709-40da-8949-9c4ead815751",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from openpyxl) (1.1.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Love Kallax. These are the best storage cubbies. I love them. Have them in my closets with the Drona boxes. My husband has some in his train room. They are a great staple to have.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install openpyxl\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('cleaned_evaluation_keyphrases_200US.xlsx')\n",
    "\n",
    "reviews = df.iloc[0:, 0].tolist()\n",
    "\n",
    "reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b69f7544-3d14-4069-b7a5-9c1f8d16febc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers\n",
      "  Cloning https://github.com/huggingface/transformers to /var/tmp/pip-req-build-bzivdm96\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /var/tmp/pip-req-build-bzivdm96\n",
      "  Resolved https://github.com/huggingface/transformers to commit 37fa1f654f17b68bbe30440c64e611f1a4d55bc7\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from transformers==4.41.0.dev0) (3.13.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from transformers==4.41.0.dev0) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from transformers==4.41.0.dev0) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from transformers==4.41.0.dev0) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from transformers==4.41.0.dev0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from transformers==4.41.0.dev0) (2024.4.16)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from transformers==4.41.0.dev0) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from transformers==4.41.0.dev0) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from transformers==4.41.0.dev0) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from transformers==4.41.0.dev0) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.41.0.dev0) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.41.0.dev0) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from requests->transformers==4.41.0.dev0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from requests->transformers==4.41.0.dev0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from requests->transformers==4.41.0.dev0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from requests->transformers==4.41.0.dev0) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7356428a-7159-4835-85d1-f8d7f3bd1b17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (0.29.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from accelerate) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from accelerate) (24.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from accelerate) (5.9.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from accelerate) (2.2.2)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from accelerate) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 13:46:51.714764: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-24 13:46:52.650066: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/lib/x86_64-linux-gnu/:/opt/conda/lib\n",
      "2024-04-24 13:46:52.650175: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/lib/x86_64-linux-gnu/:/opt/conda/lib\n",
      "2024-04-24 13:46:52.650183: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3bfc113b7244072bf1909fd84aebea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "access_token = \"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\"\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    token=access_token,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e623b3e7-26fc-4994-b3b1-0cb5ffe95252",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25th file completed in 68.25371837615967 seconds.\n",
      "50th file completed in 132.8511242866516 seconds.\n",
      "75th file completed in 201.62484049797058 seconds.\n",
      "100th file completed in 271.9474084377289 seconds.\n",
      "125th file completed in 341.9819447994232 seconds.\n",
      "150th file completed in 406.90139627456665 seconds.\n",
      "175th file completed in 481.5512399673462 seconds.\n",
      "200th file completed in 549.333931684494 seconds.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "answers = []\n",
    "for review in reviews: \n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful chatbot who only answer with the requested keyphrases and sentiments\"},\n",
    "        {\"role\": \"user\", \"content\": \"From this sentence: 'Very sturdy and sleek. Super easy to assemble, sturdy materials and construction.  I love how thin looking the shelves are: makes all your items really pop out.  Being able to choose the shelves spacing is a plus.  Sturdy enough for large books.' generate a keyphrase for each key characteristic of the product and classify the sentiment of each generated keyphrase between positive, negative or neutral. Don't give any explainations, the output should only be Keyphrase 1 - Sentiment 1, Keyphrase 2 - Sentiment 2, ...\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Sturdy - positive, sleek - positive, easy to assemble - positive\"},\n",
    "        {\"role\": \"user\", \"content\": \"From this sentence: 'Excellent small storage space. Great small piece of furniture on wheels.  Easy to assemble.  In one room it‚Äôs a plant stand with space for indoor gardening gadgets.  In another it‚Äôs a night table.  Love it so much, I bought a second one. ' generate a keyphrase for each key characteristic of the product and classify the sentiment of each generated keyphrase between positive, negative or neutral. Don't give any explainations, the output should only be Keyphrase 1 - Sentiment 1, Keyphrase 2 - Sentiment 2, ...\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Small storage space - Neutral, great piece of furniture - Positive, easy to assemble - Positive, used as plant stand - Neutral, used as night table - Neutral, love it - Positive, bought a second one - Positive.\"},\n",
    "        {\"role\": \"user\", \"content\": \"From this sentence: 'Huge Disappointment!!! Doesn't fit- too large!!. Very disappointed with these - they don't fit.  I picked these up with some other items in Renton yesterday - a 110 mile drive from me. Got home with them and they don't fit - they are too large to insert into the cubicle.  I have 2 different Kallax units - one is a 20 cubicle unit, the other an 8 cubicle unit - these will not fit into any cubicle in either of the units!!!  According to the sticker on these inserts they were manufactured (?) in Poland 2021-11-08. I saw another reviewer say that theirs were too big too. What happened to quality control??? I don't make a drive that far on a regular basis so, I'm stuck with the useless things since I won't pay shipping to return them.  Shouldn't have happened - very disappointed.' generate a keyphrase for each key characteristic of the product and classify the sentiment of each generated keyphrase between positive, negative or neutral. Don't give any explainations, the output should only be Keyphrase 1 - Sentiment 1, Keyphrase 2 - Sentiment 2, ...\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Doesn't fit - Negative, too large - Negative, useless - negative, paid shipping to return - Negative.\"},\n",
    "        {\"role\": \"user\", \"content\": \"From this sentence: 'Quality and design. This book case is well made and easy to assemble. It also looks fantastic and elevates the space it's in. Highly recommended.' generate a keyphrase for each key characteristic of the product and classify the sentiment of each generated keyphrase between positive, negative or neutral. Don't give any explainations, the output should only be Keyphrase 1 - Sentiment 1, Keyphrase 2 - Sentiment 2, ...\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Well made - Positive, easy to assemble - Positive, looks fantastic - Positive, elevates the space - Positive, highly recommended - Positive\"},\n",
    "        {\"role\": \"user\", \"content\": \"From this sentence: 'Great but.... The shelf is great. Bought it to use for bathroom storage and it fits perfectly. I took off one star because it was way to hard to assemble. Would have been great if Ikea had made the screws for adult sized hands!' generate a keyphrase for each key characteristic of the product and classify the sentiment of each generated keyphrase between positive, negative or neutral. Don't give any explainations, the output should only be Keyphrase 1 - Sentiment 1, Keyphrase 2 - Sentiment 2, ...\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Great - Positive, used for Bathroom storage - Neutral, Fits perfectly - Positive, Difficult to assemble - Negative.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"From this sentence: '{review}' generate a keyphrase for each key characteristic of the product and classify the sentiment of each generated keyphrase between positive, negative or neutral. Don't give any explainations, do not repeat any keyphrase, the output should only be Keyphrase 1 - Sentiment 1, Keyphrase 2 - Sentiment 2, ...\"},\n",
    "    ]\n",
    "\n",
    "    prompt = pipeline.tokenizer.apply_chat_template(\n",
    "            messages, \n",
    "            tokenize=False, \n",
    "            add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    terminators = [\n",
    "        pipeline.tokenizer.eos_token_id,\n",
    "        pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "    \n",
    "    outputs = pipeline(\n",
    "    prompt,\n",
    "    max_new_tokens=125,\n",
    "    eos_token_id=terminators,    \n",
    "    pad_token_id=pipeline.tokenizer.eos_token_id,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    )\n",
    "\n",
    "    answer=outputs[0][\"generated_text\"][len(prompt):]\n",
    "    answers.append(answer)\n",
    "    if (answers.index(answer) + 1) % 25 == 0: \n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(f\"{answers.index(answer) + 1}th file completed in {elapsed_time} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "764ebc6f-4961-4222-bf14-75b89f50c407",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file \"5shot_llama3.csv\" has been written successfully.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "filename = '5shot_llama3.csv'\n",
    "\n",
    "# Writing to the csv file\n",
    "with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    # Creating a csv writer object with quoting set to quote all fields\n",
    "    csvwriter = csv.writer(csvfile, delimiter=';')\n",
    "    \n",
    "    # Writing the columns\n",
    "    csvwriter.writerow(['Reviews', 'Keyphrases'])\n",
    "    \n",
    "    # Writing the data\n",
    "    for review, answer in zip(reviews, answers):\n",
    "        csvwriter.writerow([review, answer])\n",
    "\n",
    "print(f'CSV file \"{filename}\" has been written successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911608a2-0220-4a90-93e4-d6b1c8d4eafe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-tensorflow-tensorflow",
   "name": "workbench-notebooks.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m120"
  },
  "kernelspec": {
   "display_name": "TensorFlow 2-11",
   "language": "python",
   "name": "conda-env-tensorflow-tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
